{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c94cb4f",
   "metadata": {},
   "source": [
    "# Using Polars for Data Preprocessing and Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this exercise, you will walk through a complete data preprocessing workflow using Python.\n",
    "\n",
    "The goal is to take a raw dataset and transform it into a clean, structured form that is ready for analysis or modeling.\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "- Load and inspect data\n",
    "- Identify and handle missing values\n",
    "- Clean and standardize columns\n",
    "- Perform basic transformations\n",
    "- Verify the final dataset\n",
    "\n",
    "Each step is explained in detail so you can understand _why_ it is done, not just _how_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68464f18",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We are using the Polars library for data manipulation due to its performance advantages, especially with larger datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d913018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa84812",
   "metadata": {},
   "source": [
    "## Read the Input CSV File\n",
    "\n",
    "We will import the dataset using both Pandas and Polars to compare their performance. First, download the `credit_card_transactions-ibm_v2.csv` file from this [Kaggle page](https://www.kaggle.com/datasets/ealtman2019/credit-card-transactions) and place it in the same folder as your Jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2648507c",
   "metadata": {},
   "source": [
    "### `polars.read_csv()`\n",
    "\n",
    "Let's read the CSV file using Polars and measure the time taken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3872f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.02 s\n",
      "Wall time: 1.87 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24_386_900, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Year</th><th>Month</th><th>Day</th><th>Time</th><th>Amount</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:21&quot;</td><td>&quot;$134.09&quot;</td><td>&quot;Swipe Transaction&quot;</td><td>3527213246127876953</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5300</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:42&quot;</td><td>&quot;$38.48&quot;</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;06:22&quot;</td><td>&quot;$120.34&quot;</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;17:45&quot;</td><td>&quot;$128.95&quot;</td><td>&quot;Swipe Transaction&quot;</td><td>3414527459579106770</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5651</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>3</td><td>&quot;06:23&quot;</td><td>&quot;$104.71&quot;</td><td>&quot;Swipe Transaction&quot;</td><td>5817218446178736267</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5912</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:23&quot;</td><td>&quot;$-54.00&quot;</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:24&quot;</td><td>&quot;$54.00&quot;</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;07:43&quot;</td><td>&quot;$59.15&quot;</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;20:10&quot;</td><td>&quot;$43.12&quot;</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;23:10&quot;</td><td>&quot;$45.13&quot;</td><td>&quot;Chip Transaction&quot;</td><td>4751695835751691036</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5814</td><td>null</td><td>&quot;No&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24_386_900, 15)\n",
       "┌──────┬──────┬──────┬───────┬───┬─────────┬──────┬─────────┬───────────┐\n",
       "│ User ┆ Card ┆ Year ┆ Month ┆ … ┆ Zip     ┆ MCC  ┆ Errors? ┆ Is Fraud? │\n",
       "│ ---  ┆ ---  ┆ ---  ┆ ---   ┆   ┆ ---     ┆ ---  ┆ ---     ┆ ---       │\n",
       "│ i64  ┆ i64  ┆ i64  ┆ i64   ┆   ┆ f64     ┆ i64  ┆ str     ┆ str       │\n",
       "╞══════╪══════╪══════╪═══════╪═══╪═════════╪══════╪═════════╪═══════════╡\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91750.0 ┆ 5300 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91754.0 ┆ 5411 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91754.0 ┆ 5411 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91754.0 ┆ 5651 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91750.0 ┆ 5912 ┆ null    ┆ No        │\n",
       "│ …    ┆ …    ┆ …    ┆ …     ┆ … ┆ …       ┆ …    ┆ …       ┆ …         │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 3054.0  ┆ 5541 ┆ null    ┆ No        │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 3054.0  ┆ 5541 ┆ null    ┆ No        │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 3054.0  ┆ 4121 ┆ null    ┆ No        │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 3054.0  ┆ 4121 ┆ null    ┆ No        │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 3054.0  ┆ 5814 ┆ null    ┆ No        │\n",
       "└──────┴──────┴──────┴───────┴───┴─────────┴──────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_polars = pl.read_csv(\"credit_card_transactions-ibm_v2.csv\")\n",
    "df_polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499ba21",
   "metadata": {},
   "source": [
    "### Benchmarking with Pandas\n",
    "\n",
    "You can compare the time taken by Polars with that of Pandas for reading the same CSV file.\n",
    "\n",
    "```python\n",
    "%%time\n",
    "df_pandas = pd.read_csv(\"credit_card_transactions-ibm_v2.csv\")\n",
    "```\n",
    "\n",
    "The execution time will vary based on your system, but Polars is generally expected to be much faster for larger datasets. In my desktop with 32GB RAM and an 13th Gen Intel(R) Core(TM) i7-13700, Polars took approximately 1 second while Pandas took around 22 seconds. That's more than a 20x speedup!\n",
    "\n",
    "`pandas` time result:\n",
    "\n",
    "```\n",
    "CPU times: total: 3 s\n",
    "Wall time: 22.6 s\n",
    "```\n",
    "\n",
    "`polars` time result:\n",
    "\n",
    "```\n",
    "CPU times: total: 1.02 s\n",
    "Wall time: 941 ms\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7b5bd",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae97e5a",
   "metadata": {},
   "source": [
    "### Convert `\"Amount\"` column to a numeric type\n",
    "\n",
    "The code below performs data type conversion on the `\"Amount\"` column. It utilizes Polars' expression API to remove \"$\" and \",\" characters via `replace_all()`, subsequently casting the cleaned values to `Float64` to overwrite the existing column with numeric data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5467c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns(\n",
    "    pl.col(\"Amount\")\n",
    "    .str.replace_all(r\"[$,]\", \"\")  # remove $ (and commas, just in case)\n",
    "    .cast(pl.Float64)\n",
    "    .alias(\"Amount\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b643cd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Year</th><th>Month</th><th>Day</th><th>Time</th><th>Amount</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:21&quot;</td><td>134.09</td><td>&quot;Swipe Transaction&quot;</td><td>3527213246127876953</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5300</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:42&quot;</td><td>38.48</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;06:22&quot;</td><td>120.34</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 15)\n",
       "┌──────┬──────┬──────┬───────┬───┬─────────┬──────┬─────────┬───────────┐\n",
       "│ User ┆ Card ┆ Year ┆ Month ┆ … ┆ Zip     ┆ MCC  ┆ Errors? ┆ Is Fraud? │\n",
       "│ ---  ┆ ---  ┆ ---  ┆ ---   ┆   ┆ ---     ┆ ---  ┆ ---     ┆ ---       │\n",
       "│ i64  ┆ i64  ┆ i64  ┆ i64   ┆   ┆ f64     ┆ i64  ┆ str     ┆ str       │\n",
       "╞══════╪══════╪══════╪═══════╪═══╪═════════╪══════╪═════════╪═══════════╡\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91750.0 ┆ 5300 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91754.0 ┆ 5411 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 91754.0 ┆ 5411 ┆ null    ┆ No        │\n",
       "└──────┴──────┴──────┴───────┴───┴─────────┴──────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850c3d9",
   "metadata": {},
   "source": [
    "The output confirms that the `\"Amount\"` column has been successfully converted to a `f64` (Float64) data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bec96",
   "metadata": {},
   "source": [
    "### Check the Schema\n",
    "\n",
    "#### What is a Schema in Polars?\n",
    "\n",
    "In Polars, the **schema** is a fixed mapping of column names to their specific data types (dtypes). Unlike some other data libraries, Polars is built on the Apache Arrow memory format, which requires every column to have a strictly defined type from the moment the DataFrame is initialized. This schema acts as a \"contract\" for your data; if you try to perform a string operation on a column that the schema defines as an integer, Polars will stop you immediately with a clear error. This strictness is a core reason why Polars is so fast and memory-efficient---it knows exactly how much space to allocate in memory and which CPU instructions to use before it even touches the data.\n",
    "\n",
    "The fundamental difference between Polars and pandas lies in how they handle type inference and consistency:\n",
    "\n",
    "- **Predictability vs. Flexibility:** Pandas is \"lazy\" and flexible with types, often defaulting to the generic `object` dtype if it encounters mixed data (like a column with both numbers and strings). This can lead to \"Object\" columns that swallow up memory and slow down your code. Polars, conversely, is \"eager\" about types; it does not allow mixed types in a single column.\n",
    "\n",
    "- **The Schema Check:** In pandas, you often don't know a calculation will fail until the code has already been running for several minutes. Because Polars has a defined schema and a lazy execution engine, it can inspect your entire query plan and check the schema for type mismatches _before_ it actually processes a single row of data.\n",
    "\n",
    "- **Null Handling:** While pandas historically used `NaN` (a float value) to represent missing numbers - which could accidentally change an integer column into a float column - Polars handles nulls using a separate bitmask. This ensures that your integers stay integers, keeping your schema stable throughout your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492af50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('User', Int64),\n",
       "        ('Card', Int64),\n",
       "        ('Year', Int64),\n",
       "        ('Month', Int64),\n",
       "        ('Day', Int64),\n",
       "        ('Time', String),\n",
       "        ('Amount', Float64),\n",
       "        ('Use Chip', String),\n",
       "        ('Merchant Name', Int64),\n",
       "        ('Merchant City', String),\n",
       "        ('Merchant State', String),\n",
       "        ('Zip', Float64),\n",
       "        ('MCC', Int64),\n",
       "        ('Errors?', String),\n",
       "        ('Is Fraud?', String)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e990119",
   "metadata": {},
   "source": [
    "The `df_polars.schema` output is a structured dictionary-like object that acts as the blueprint for your DataFrame. It maps every column name to its specific Polars data type (such as `String`, `Float64`, or `Int64`). Unlike a simple list of names, this schema is the source of truth for the Query Optimizer; it allows Polars to validate operations - like ensuring you aren't trying to add a number to a date - without having to scan the actual data. When you look at this output, you are seeing the strict definitions that Polars uses to allocate memory and plan the most efficient way to execute your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01f62e",
   "metadata": {},
   "source": [
    "### Create a timestamp column from the date time components\n",
    "\n",
    "The code below merges fragmented date and time components into a single, unified Datetime column named `\"timestamp\"`. By using `pl.datetime()`, you are instructing Polars to reach into the individual \"Year\", \"Month\", and \"Day\" columns and combine them with hours and minutes extracted from the `\"Time\"` string. To get those specific time units, the code uses `.str.slice()` to \"cut\" the hour and minute portions out of the string and casts them to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1c71af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24_386_900, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Year</th><th>Month</th><th>Day</th><th>Time</th><th>Amount</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th><th>Datetime</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:21&quot;</td><td>134.09</td><td>&quot;Swipe Transaction&quot;</td><td>3527213246127876953</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5300</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-01 06:21:00</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:42&quot;</td><td>38.48</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-01 06:42:00</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;06:22&quot;</td><td>120.34</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-02 06:22:00</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;17:45&quot;</td><td>128.95</td><td>&quot;Swipe Transaction&quot;</td><td>3414527459579106770</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5651</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-02 17:45:00</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>3</td><td>&quot;06:23&quot;</td><td>104.71</td><td>&quot;Swipe Transaction&quot;</td><td>5817218446178736267</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5912</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-03 06:23:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:23&quot;</td><td>-54.0</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-27 22:23:00</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:24&quot;</td><td>54.0</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-27 22:24:00</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;07:43&quot;</td><td>59.15</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 07:43:00</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;20:10&quot;</td><td>43.12</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 20:10:00</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;23:10&quot;</td><td>45.13</td><td>&quot;Chip Transaction&quot;</td><td>4751695835751691036</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5814</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 23:10:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24_386_900, 16)\n",
       "┌──────┬──────┬──────┬───────┬───┬──────┬─────────┬───────────┬─────────────────────┐\n",
       "│ User ┆ Card ┆ Year ┆ Month ┆ … ┆ MCC  ┆ Errors? ┆ Is Fraud? ┆ Datetime            │\n",
       "│ ---  ┆ ---  ┆ ---  ┆ ---   ┆   ┆ ---  ┆ ---     ┆ ---       ┆ ---                 │\n",
       "│ i64  ┆ i64  ┆ i64  ┆ i64   ┆   ┆ i64  ┆ str     ┆ str       ┆ datetime[μs]        │\n",
       "╞══════╪══════╪══════╪═══════╪═══╪══════╪═════════╪═══════════╪═════════════════════╡\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 5300 ┆ null    ┆ No        ┆ 2002-09-01 06:21:00 │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 5411 ┆ null    ┆ No        ┆ 2002-09-01 06:42:00 │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 5411 ┆ null    ┆ No        ┆ 2002-09-02 06:22:00 │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 5651 ┆ null    ┆ No        ┆ 2002-09-02 17:45:00 │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 5912 ┆ null    ┆ No        ┆ 2002-09-03 06:23:00 │\n",
       "│ …    ┆ …    ┆ …    ┆ …     ┆ … ┆ …    ┆ …       ┆ …         ┆ …                   │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 5541 ┆ null    ┆ No        ┆ 2020-02-27 22:23:00 │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 5541 ┆ null    ┆ No        ┆ 2020-02-27 22:24:00 │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 4121 ┆ null    ┆ No        ┆ 2020-02-28 07:43:00 │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 4121 ┆ null    ┆ No        ┆ 2020-02-28 20:10:00 │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 5814 ┆ null    ┆ No        ┆ 2020-02-28 23:10:00 │\n",
       "└──────┴──────┴──────┴───────┴───┴──────┴─────────┴───────────┴─────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars = df_polars.with_columns(\n",
    "    pl.datetime(\n",
    "        pl.col(\"Year\"),\n",
    "        pl.col(\"Month\"),\n",
    "        pl.col(\"Day\"),\n",
    "        pl.col(\"Time\").str.slice(0, 2).cast(pl.Int32),\n",
    "        pl.col(\"Time\").str.slice(3, 2).cast(pl.Int32),\n",
    "    ).alias(\"Datetime\")\n",
    ")\n",
    "\n",
    "df_polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35903c69",
   "metadata": {},
   "source": [
    "The primary benefit of this transformation is that it shifts your dataset from a static table into a time-series format. Instead of treating \"Year\" and \"Month\" as independent categories, Polars now understands the linear flow of time between transactions. This allows you to perform advanced chronological operations—such as calculating the time elapsed between purchases, sorting transactions by occurrence, or resampling the data to see fraud trends by hour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058195c9",
   "metadata": {},
   "source": [
    "### (Optional) Write to a Parquet File\n",
    "\n",
    "Parquet is a columnar storage file format that is optimized for performance and efficiency. It allows for faster read and write operations compared to CSV, especially with larger datasets. By writing the cleaned DataFrame to a Parquet file, you can significantly reduce the time it takes to load the data in future analyses, as Parquet files are designed for efficient data retrieval and storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c575be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Amount</th><th>Datetime</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>datetime[μs]</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>134.09</td><td>2002-09-01 06:21:00</td><td>&quot;Swipe Transaction&quot;</td><td>3527213246127876953</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5300</td><td>null</td><td>&quot;No&quot;</td></tr><tr><td>0</td><td>0</td><td>38.48</td><td>2002-09-01 06:42:00</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 12)\n",
       "┌──────┬──────┬────────┬─────────────────────┬───┬─────────┬──────┬─────────┬───────────┐\n",
       "│ User ┆ Card ┆ Amount ┆ Datetime            ┆ … ┆ Zip     ┆ MCC  ┆ Errors? ┆ Is Fraud? │\n",
       "│ ---  ┆ ---  ┆ ---    ┆ ---                 ┆   ┆ ---     ┆ ---  ┆ ---     ┆ ---       │\n",
       "│ i64  ┆ i64  ┆ f64    ┆ datetime[μs]        ┆   ┆ f64     ┆ i64  ┆ str     ┆ str       │\n",
       "╞══════╪══════╪════════╪═════════════════════╪═══╪═════════╪══════╪═════════╪═══════════╡\n",
       "│ 0    ┆ 0    ┆ 134.09 ┆ 2002-09-01 06:21:00 ┆ … ┆ 91750.0 ┆ 5300 ┆ null    ┆ No        │\n",
       "│ 0    ┆ 0    ┆ 38.48  ┆ 2002-09-01 06:42:00 ┆ … ┆ 91754.0 ┆ 5411 ┆ null    ┆ No        │\n",
       "└──────┴──────┴────────┴─────────────────────┴───┴─────────┴──────┴─────────┴───────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove redundant date and time component columns\n",
    "df_for_parquet = df_polars.drop([\"Year\", \"Month\", \"Day\", \"Time\"])\n",
    "\n",
    "# Reorder columns to match the original CSV structure, with the new \"Datetime\" column in a logical position\n",
    "first_columns = [\"User\", \"Card\", \"Amount\", \"Datetime\"]\n",
    "df_for_parquet = df_for_parquet.select([*first_columns, pl.exclude(first_columns)])\n",
    "\n",
    "df_for_parquet.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b81347",
   "metadata": {},
   "source": [
    "Write to a parquet file using Polars' `write_parquet()` method. This will save the cleaned DataFrame in a more efficient format for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b6f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_parquet.write_parquet(\"credit_card_transactions-ibm_v2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da589c",
   "metadata": {},
   "source": [
    ":::{tip} Columnar vs row-based storage\n",
    "\n",
    "CSV files are row-oriented.\n",
    "\n",
    "```plaintext\n",
    "row1: a,b,c,d,e\n",
    "row2: a,b,c,d,e\n",
    "row3: a,b,c,d,e\n",
    "```\n",
    "\n",
    "To read **one column**, the engine must:\n",
    "\n",
    "- read every row\n",
    "- parse every value\n",
    "- throw most of it away\n",
    "\n",
    "On the other hand Parquet files are column-oriented.\n",
    "\n",
    "```plaintext\n",
    "col_a: a a a\n",
    "col_b: b b b\n",
    "col_c: c c c\n",
    "col_d: d d d\n",
    "col_e: e e e\n",
    "```\n",
    "\n",
    "If your query only needs `Amount` and `Merchant Name`:\n",
    "\n",
    "- CSV parses everything.\n",
    "- Parquet only reads those two columns.\n",
    "\n",
    "This is why Parquet is dramatically faster for analytics.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e9022",
   "metadata": {},
   "source": [
    ":::{info} Parquet's compression\n",
    "\n",
    "### CSV compression is \"dumb\"\n",
    "\n",
    "- You gzip the whole file\n",
    "- You must decompress the entire thing to read any part\n",
    "- No awareness of data types\n",
    "\n",
    "### Parquet compression is \"smart\"\n",
    "\n",
    "- Each column compressed separately\n",
    "- Repeated values occupy extremely small space\n",
    "- Integers, floats, timestamps all compress differently\n",
    "- Engines can skip compressed blocks they are not queried\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef75b1",
   "metadata": {},
   "source": [
    "### Payment method frequency analysis\n",
    "\n",
    "The code below provides a high-level summary of the payment methods used across your credit card dataset. The `.value_counts()` method performs a frequency analysis on the `\"Use Chip\"` column, identifying every unique entry (Chip, Online, and Swipe transactions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ee6fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Use Chip</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Swipe Transaction&quot;</td><td>15386082</td></tr><tr><td>&quot;Chip Transaction&quot;</td><td>6287598</td></tr><tr><td>&quot;Online Transaction&quot;</td><td>2713220</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────────────┬──────────┐\n",
       "│ Use Chip           ┆ count    │\n",
       "│ ---                ┆ ---      │\n",
       "│ str                ┆ u32      │\n",
       "╞════════════════════╪══════════╡\n",
       "│ Swipe Transaction  ┆ 15386082 │\n",
       "│ Chip Transaction   ┆ 6287598  │\n",
       "│ Online Transaction ┆ 2713220  │\n",
       "└────────────────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars[\"Use Chip\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71108903",
   "metadata": {},
   "source": [
    "Looking at the numbers, you can see that Swipe Transactions are the dominant payment method in this dataset with over 15 million entries, followed by Chip Transactions at roughly 6.2 million. This breakdown is essential for understanding consumer behavior or detecting potential fraud patterns, as certain types of transactions (like \"Online\" vs. \"Swipe\") carry different risk profiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8684be4",
   "metadata": {},
   "source": [
    "### Fraud distribution analysis\n",
    "\n",
    "The code below shows the frequency of the `\"Is Fraud?\"` column to determine the distribution of legitimate versus fraudulent transactions within your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a0f492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Is Fraud?</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;No&quot;</td><td>24357143</td></tr><tr><td>&quot;Yes&quot;</td><td>29757</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬──────────┐\n",
       "│ Is Fraud? ┆ count    │\n",
       "│ ---       ┆ ---      │\n",
       "│ str       ┆ u32      │\n",
       "╞═══════════╪══════════╡\n",
       "│ No        ┆ 24357143 │\n",
       "│ Yes       ┆ 29757    │\n",
       "└───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars[\"Is Fraud?\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47554251",
   "metadata": {},
   "source": [
    "The data reveals that the overwhelming majority of transactions - over 24.3 million - are flagged as \"No\", while only 29,757 are flagged as \"Yes\". While the fraudulent cases represent a very small fraction of the total volume (roughly 0.12%), identifying this minority is the primary goal of most credit card analytics. Understanding this ratio is a critical first step before building a machine learning model, as it tells you that you'll need specialized techniques, like oversampling or specific loss functions, to account for the rarity of fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32914c9",
   "metadata": {},
   "source": [
    "### Flag suspicious transactions based on amount\n",
    "\n",
    "The code below performs feature engineering by creating three new boolean (`True`/`False`) indicators based on specific transaction characteristics. By using `with_columns()` with a list of expressions, Polars efficiently evaluates these conditions in parallel, adding descriptive flags that make the dataset much easier to filter and analyze. Specifically, it identifies refunds (amounts less than zero), large transactions (amounts exceeding $500), and online activity (where the \"Use Chip\" status matches \"Online Transaction\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26658f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24_386_900, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Year</th><th>Month</th><th>Day</th><th>Time</th><th>Amount</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th><th>Datetime</th><th>is_refund</th><th>large_txn</th><th>is_online</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>bool</td><td>bool</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:21&quot;</td><td>134.09</td><td>&quot;Swipe Transaction&quot;</td><td>3527213246127876953</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5300</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-01 06:21:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>1</td><td>&quot;06:42&quot;</td><td>38.48</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-01 06:42:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;06:22&quot;</td><td>120.34</td><td>&quot;Swipe Transaction&quot;</td><td>-727612092139916043</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5411</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-02 06:22:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>2</td><td>&quot;17:45&quot;</td><td>128.95</td><td>&quot;Swipe Transaction&quot;</td><td>3414527459579106770</td><td>&quot;Monterey Park&quot;</td><td>&quot;CA&quot;</td><td>91754.0</td><td>5651</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-02 17:45:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>0</td><td>0</td><td>2002</td><td>9</td><td>3</td><td>&quot;06:23&quot;</td><td>104.71</td><td>&quot;Swipe Transaction&quot;</td><td>5817218446178736267</td><td>&quot;La Verne&quot;</td><td>&quot;CA&quot;</td><td>91750.0</td><td>5912</td><td>null</td><td>&quot;No&quot;</td><td>2002-09-03 06:23:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:23&quot;</td><td>-54.0</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-27 22:23:00</td><td>true</td><td>false</td><td>false</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>27</td><td>&quot;22:24&quot;</td><td>54.0</td><td>&quot;Chip Transaction&quot;</td><td>-5162038175624867091</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5541</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-27 22:24:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;07:43&quot;</td><td>59.15</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 07:43:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;20:10&quot;</td><td>43.12</td><td>&quot;Chip Transaction&quot;</td><td>2500998799892805156</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>4121</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 20:10:00</td><td>false</td><td>false</td><td>false</td></tr><tr><td>1999</td><td>1</td><td>2020</td><td>2</td><td>28</td><td>&quot;23:10&quot;</td><td>45.13</td><td>&quot;Chip Transaction&quot;</td><td>4751695835751691036</td><td>&quot;Merrimack&quot;</td><td>&quot;NH&quot;</td><td>3054.0</td><td>5814</td><td>null</td><td>&quot;No&quot;</td><td>2020-02-28 23:10:00</td><td>false</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24_386_900, 19)\n",
       "┌──────┬──────┬──────┬───────┬───┬─────────────────────┬───────────┬───────────┬───────────┐\n",
       "│ User ┆ Card ┆ Year ┆ Month ┆ … ┆ Datetime            ┆ is_refund ┆ large_txn ┆ is_online │\n",
       "│ ---  ┆ ---  ┆ ---  ┆ ---   ┆   ┆ ---                 ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ i64  ┆ i64  ┆ i64  ┆ i64   ┆   ┆ datetime[μs]        ┆ bool      ┆ bool      ┆ bool      │\n",
       "╞══════╪══════╪══════╪═══════╪═══╪═════════════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 2002-09-01 06:21:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 2002-09-01 06:42:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 2002-09-02 06:22:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 2002-09-02 17:45:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 0    ┆ 0    ┆ 2002 ┆ 9     ┆ … ┆ 2002-09-03 06:23:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ …    ┆ …    ┆ …    ┆ …     ┆ … ┆ …                   ┆ …         ┆ …         ┆ …         │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 2020-02-27 22:23:00 ┆ true      ┆ false     ┆ false     │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 2020-02-27 22:24:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 2020-02-28 07:43:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 2020-02-28 20:10:00 ┆ false     ┆ false     ┆ false     │\n",
       "│ 1999 ┆ 1    ┆ 2020 ┆ 2     ┆ … ┆ 2020-02-28 23:10:00 ┆ false     ┆ false     ┆ false     │\n",
       "└──────┴──────┴──────┴───────┴───┴─────────────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars.with_columns(\n",
    "    [\n",
    "        (pl.col(\"Amount\") < 0).alias(\"is_refund\"),\n",
    "        (pl.col(\"Amount\") > 500).alias(\"large_txn\"),\n",
    "        (pl.col(\"Use Chip\") == \"Online Transaction\").alias(\"is_online\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de7b80",
   "metadata": {},
   "source": [
    "These \"flag\" columns can be useful for both exploratory analysis and machine learning. Instead of writing complex filters repeatedly, you can now quickly segment your data. For example, to see if \"large transactions\" are more likely to be \"fraudulent\" or to calculate the total volume of \"online\" versus in-person sales. This step transforms raw data into behavioral features, providing the model or the analyst with clear, binary signals that highlight high-interest events within the transaction stream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df78f836",
   "metadata": {},
   "source": [
    "### Filter rows based on conditions\n",
    "\n",
    "You can also apply a filter to isolate a very specific subset of your data: online refunds. By passing multiple conditions into the `.filter()` method, Polars treats them as a logical AND operation, meaning a transaction will only remain in the resulting DataFrame if it is both a negative value (the `\"is_refund\"` condition) and was conducted as an \"Online Transaction\" (the `\"is_online\"` condition).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a3948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13_499, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>Card</th><th>Year</th><th>Month</th><th>Day</th><th>Time</th><th>Amount</th><th>Use Chip</th><th>Merchant Name</th><th>Merchant City</th><th>Merchant State</th><th>Zip</th><th>MCC</th><th>Errors?</th><th>Is Fraud?</th><th>Datetime</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>str</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2004</td><td>12</td><td>10</td><td>&quot;20:45&quot;</td><td>-100.0</td><td>&quot;Online Transaction&quot;</td><td>7501849281341469857</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2004-12-10 20:45:00</td></tr><tr><td>0</td><td>0</td><td>2010</td><td>10</td><td>8</td><td>&quot;18:00&quot;</td><td>-393.0</td><td>&quot;Online Transaction&quot;</td><td>333722291367506728</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2010-10-08 18:00:00</td></tr><tr><td>0</td><td>0</td><td>2011</td><td>12</td><td>19</td><td>&quot;12:50&quot;</td><td>-443.0</td><td>&quot;Online Transaction&quot;</td><td>333722291367506728</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2011-12-19 12:50:00</td></tr><tr><td>0</td><td>0</td><td>2015</td><td>11</td><td>20</td><td>&quot;07:42&quot;</td><td>-473.0</td><td>&quot;Online Transaction&quot;</td><td>-8566951830324093739</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>3640</td><td>null</td><td>&quot;Yes&quot;</td><td>2015-11-20 07:42:00</td></tr><tr><td>0</td><td>2</td><td>2017</td><td>2</td><td>21</td><td>&quot;08:03&quot;</td><td>-461.0</td><td>&quot;Online Transaction&quot;</td><td>7501849281341469857</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2017-02-21 08:03:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1998</td><td>0</td><td>2019</td><td>2</td><td>27</td><td>&quot;15:09&quot;</td><td>-441.0</td><td>&quot;Online Transaction&quot;</td><td>3694722044710185708</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2019-02-27 15:09:00</td></tr><tr><td>1998</td><td>0</td><td>2019</td><td>11</td><td>27</td><td>&quot;11:08&quot;</td><td>-354.0</td><td>&quot;Online Transaction&quot;</td><td>3694722044710185708</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2019-11-27 11:08:00</td></tr><tr><td>1998</td><td>0</td><td>2019</td><td>12</td><td>29</td><td>&quot;19:40&quot;</td><td>-122.0</td><td>&quot;Online Transaction&quot;</td><td>3694722044710185708</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2019-12-29 19:40:00</td></tr><tr><td>1999</td><td>1</td><td>2018</td><td>10</td><td>24</td><td>&quot;01:48&quot;</td><td>-419.0</td><td>&quot;Online Transaction&quot;</td><td>7501849281341469857</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2018-10-24 01:48:00</td></tr><tr><td>1999</td><td>1</td><td>2019</td><td>6</td><td>16</td><td>&quot;16:55&quot;</td><td>-154.0</td><td>&quot;Online Transaction&quot;</td><td>333722291367506728</td><td>&quot;ONLINE&quot;</td><td>null</td><td>null</td><td>4722</td><td>null</td><td>&quot;No&quot;</td><td>2019-06-16 16:55:00</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13_499, 16)\n",
       "┌──────┬──────┬──────┬───────┬───┬──────┬─────────┬───────────┬─────────────────────┐\n",
       "│ User ┆ Card ┆ Year ┆ Month ┆ … ┆ MCC  ┆ Errors? ┆ Is Fraud? ┆ Datetime            │\n",
       "│ ---  ┆ ---  ┆ ---  ┆ ---   ┆   ┆ ---  ┆ ---     ┆ ---       ┆ ---                 │\n",
       "│ i64  ┆ i64  ┆ i64  ┆ i64   ┆   ┆ i64  ┆ str     ┆ str       ┆ datetime[μs]        │\n",
       "╞══════╪══════╪══════╪═══════╪═══╪══════╪═════════╪═══════════╪═════════════════════╡\n",
       "│ 0    ┆ 0    ┆ 2004 ┆ 12    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2004-12-10 20:45:00 │\n",
       "│ 0    ┆ 0    ┆ 2010 ┆ 10    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2010-10-08 18:00:00 │\n",
       "│ 0    ┆ 0    ┆ 2011 ┆ 12    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2011-12-19 12:50:00 │\n",
       "│ 0    ┆ 0    ┆ 2015 ┆ 11    ┆ … ┆ 3640 ┆ null    ┆ Yes       ┆ 2015-11-20 07:42:00 │\n",
       "│ 0    ┆ 2    ┆ 2017 ┆ 2     ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2017-02-21 08:03:00 │\n",
       "│ …    ┆ …    ┆ …    ┆ …     ┆ … ┆ …    ┆ …       ┆ …         ┆ …                   │\n",
       "│ 1998 ┆ 0    ┆ 2019 ┆ 2     ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2019-02-27 15:09:00 │\n",
       "│ 1998 ┆ 0    ┆ 2019 ┆ 11    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2019-11-27 11:08:00 │\n",
       "│ 1998 ┆ 0    ┆ 2019 ┆ 12    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2019-12-29 19:40:00 │\n",
       "│ 1999 ┆ 1    ┆ 2018 ┆ 10    ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2018-10-24 01:48:00 │\n",
       "│ 1999 ┆ 1    ┆ 2019 ┆ 6     ┆ … ┆ 4722 ┆ null    ┆ No        ┆ 2019-06-16 16:55:00 │\n",
       "└──────┴──────┴──────┴───────┴───┴──────┴─────────┴───────────┴─────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_polars.filter(\n",
    "    (pl.col(\"Amount\") < 0).alias(\"is_refund\"),\n",
    "    (pl.col(\"Use Chip\") == \"Online Transaction\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acaacd5",
   "metadata": {},
   "source": [
    "### Per-user aggregation\n",
    "\n",
    "The code below performs a user-level aggregation, collapsing millions of individual transaction records into a concise summary of spending behavior for each unique customer. By using `group_by(\"User\")`, you are instructing Polars to organize the data into buckets based on the individual user ID. The `.agg()` function then calculates three key metrics for each bucket:\n",
    "\n",
    "1. the total volume of money spent,\n",
    "2. the average cost per purchase, and\n",
    "3. the total count of transactions (using `pl.len()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191a18d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_000, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>User</th><th>total_spent</th><th>average_amount</th><th>num_transactions</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>533</td><td>790875.13</td><td>28.146024</td><td>28099</td></tr><tr><td>399</td><td>996009.52</td><td>50.339104</td><td>19786</td></tr><tr><td>1319</td><td>179848.65</td><td>37.942753</td><td>4740</td></tr><tr><td>265</td><td>10191.19</td><td>30.696355</td><td>332</td></tr><tr><td>792</td><td>803050.74</td><td>50.723266</td><td>15832</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1295</td><td>588974.09</td><td>36.340723</td><td>16207</td></tr><tr><td>262</td><td>1.4352e6</td><td>21.078546</td><td>68089</td></tr><tr><td>908</td><td>419659.94</td><td>68.292911</td><td>6145</td></tr><tr><td>509</td><td>889922.13</td><td>51.941991</td><td>17133</td></tr><tr><td>1828</td><td>19309.99</td><td>62.09</td><td>311</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_000, 4)\n",
       "┌──────┬─────────────┬────────────────┬──────────────────┐\n",
       "│ User ┆ total_spent ┆ average_amount ┆ num_transactions │\n",
       "│ ---  ┆ ---         ┆ ---            ┆ ---              │\n",
       "│ i64  ┆ f64         ┆ f64            ┆ u32              │\n",
       "╞══════╪═════════════╪════════════════╪══════════════════╡\n",
       "│ 533  ┆ 790875.13   ┆ 28.146024      ┆ 28099            │\n",
       "│ 399  ┆ 996009.52   ┆ 50.339104      ┆ 19786            │\n",
       "│ 1319 ┆ 179848.65   ┆ 37.942753      ┆ 4740             │\n",
       "│ 265  ┆ 10191.19    ┆ 30.696355      ┆ 332              │\n",
       "│ 792  ┆ 803050.74   ┆ 50.723266      ┆ 15832            │\n",
       "│ …    ┆ …           ┆ …              ┆ …                │\n",
       "│ 1295 ┆ 588974.09   ┆ 36.340723      ┆ 16207            │\n",
       "│ 262  ┆ 1.4352e6    ┆ 21.078546      ┆ 68089            │\n",
       "│ 908  ┆ 419659.94   ┆ 68.292911      ┆ 6145             │\n",
       "│ 509  ┆ 889922.13   ┆ 51.941991      ┆ 17133            │\n",
       "│ 1828 ┆ 19309.99    ┆ 62.09          ┆ 311              │\n",
       "└──────┴─────────────┴────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stats = df_polars.group_by(\"User\").agg(\n",
    "    [\n",
    "        pl.col(\"Amount\").sum().alias(\"total_spent\"),\n",
    "        pl.col(\"Amount\").mean().alias(\"average_amount\"),\n",
    "        pl.len().alias(\"num_transactions\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "user_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278dd2bf",
   "metadata": {},
   "source": [
    "Rolling / window features (SQL-like mental model):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffba9f",
   "metadata": {},
   "source": [
    "### 10 most recent transactions rolling sum\n",
    "\n",
    "You can also compute rolling aggregates to capture recent behavior. The code below calculates a rolling sum of the `\"Amount\"` column over the last 10 transactions for each user. By using `.over(\"User\")`, you ensure that the rolling calculation is performed separately for each individual customer, maintaining the integrity of user-specific spending patterns. The `.rolling_sum(window_size=10)` function then computes the sum of the last 10 transaction amounts, providing insight into recent spending trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68114985",
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "unable to find column \"timestamp\"; valid columns: [\"User\", \"Card\", \"Year\", \"Month\", \"Day\", \"Time\", \"Amount\", \"Use Chip\", \"Merchant Name\", \"Merchant City\", \"Merchant State\", \"Zip\", \"MCC\", \"Errors?\", \"Is Fraud?\", \"Datetime\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mColumnNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_rolling = \u001b[43mdf_polars\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.with_columns(\n\u001b[32m      2\u001b[39m     pl.col(\u001b[33m\"\u001b[39m\u001b[33mAmount\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m     .rolling_sum(window_size=\u001b[32m10\u001b[39m)\n\u001b[32m      4\u001b[39m     .over(\u001b[33m\"\u001b[39m\u001b[33mUser\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     .alias(\u001b[33m\"\u001b[39m\u001b[33mrolling_amount_sum_10\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m df_rolling\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\polars\\dataframe\\frame.py:5965\u001b[39m, in \u001b[36mDataFrame.sort\u001b[39m\u001b[34m(self, by, descending, nulls_last, multithreaded, maintain_order, *more_by)\u001b[39m\n\u001b[32m   5867\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5868\u001b[39m \u001b[33;03mSort the dataframe by the given columns.\u001b[39;00m\n\u001b[32m   5869\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5951\u001b[39m \u001b[33;03m└──────┴─────┴─────┘\u001b[39;00m\n\u001b[32m   5952\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5953\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazyframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QueryOptFlags\n\u001b[32m   5955\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   5956\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5957\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5958\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5959\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmore_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5960\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5961\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnulls_last\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnulls_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5962\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmultithreaded\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultithreaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaintain_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaintain_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5964\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m5965\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mQueryOptFlags\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5966\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\polars\\_utils\\deprecation.py:97\u001b[39m, in \u001b[36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33min-memory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstreaming\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\polars\\lazyframe\\opt_flags.py:324\u001b[39m, in \u001b[36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m         optflags = cb(optflags, kwargs.pop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[32m    323\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33moptimizations\u001b[39m\u001b[33m\"\u001b[39m] = optflags\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\polars\\lazyframe\\frame.py:2429\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[39m\n\u001b[32m   2427\u001b[39m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[32m   2428\u001b[39m callback = _kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mpost_opt_callback\u001b[39m\u001b[33m\"\u001b[39m, callback)\n\u001b[32m-> \u001b[39m\u001b[32m2429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mColumnNotFoundError\u001b[39m: unable to find column \"timestamp\"; valid columns: [\"User\", \"Card\", \"Year\", \"Month\", \"Day\", \"Time\", \"Amount\", \"Use Chip\", \"Merchant Name\", \"Merchant City\", \"Merchant State\", \"Zip\", \"MCC\", \"Errors?\", \"Is Fraud?\", \"Datetime\"]"
     ]
    }
   ],
   "source": [
    "df_rolling = df_polars.sort([\"User\", \"timestamp\"]).with_columns(\n",
    "    pl.col(\"Amount\")\n",
    "    .rolling_sum(window_size=10)\n",
    "    .over(\"User\")\n",
    "    .alias(\"rolling_amount_sum_10\")\n",
    ")\n",
    "\n",
    "df_rolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bc93a",
   "metadata": {},
   "source": [
    "The `.over(\"User\")` part is the direct counterpart to SQL's `PARTITION BY User`. It ensures the rolling calculation \"resets\" or stays contained within each specific user's history, preventing a transaction from User A from being included in the sum for User B. In SQL terms, this operation is essentially:\n",
    "\n",
    "```sql\n",
    "SUM(Amount) OVER (\n",
    "    PARTITION BY User\n",
    "    ORDER BY timestamp\n",
    "    ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n",
    ")\n",
    "```\n",
    "\n",
    "This technique can be used in real-time fraud detection. By tracking a \"rolling sum,\" you can detect \"velocity attacks\" where a card is used for many large purchases in a very short window. If this rolling sum spikes suddenly compared to the user's historical average, it provides a much stronger signal for fraud than any single transaction could on its own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b579c0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You have completed a full data preprocessing pipeline from raw data to a cleaned dataset. Then, you performed feature engineering and aggregation to extract meaningful insights.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
