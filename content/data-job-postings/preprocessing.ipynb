{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963f38d3",
   "metadata": {},
   "source": [
    "# Data Job Postings Analysis\n",
    "\n",
    "In this case study, we will analyze a dataset of job postings for data science and analytics roles. The dataset contains various columns such as job title, company, location, salary, job description, and required skills. However, some columns may have mostly missing values, which we will need to handle during preprocessing. For example, most companies may prefer not to disclose salary information, resulting in a column with many null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab3280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867850d",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc32bac",
   "metadata": {},
   "source": [
    "The dataset is uploaded to a GitHub repository for convenience. You can also access the original dataset on Hugging Face Datasets at [`lukebarousse/data_jobs`](https://huggingface.co/datasets/lukebarousse/data_jobs). The original CSV file is quite large (~230 MB) due to the large number of rows and text fields, but it has been converted to Parquet format for this case study, which significantly reduces the file size to ~30 MB while preserving all data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9e7176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (785_741, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_title_short</th><th>job_title</th><th>job_location</th><th>job_via</th><th>job_schedule_type</th><th>job_work_from_home</th><th>search_location</th><th>job_posted_date</th><th>job_no_degree_mention</th><th>job_health_insurance</th><th>job_country</th><th>salary_rate</th><th>salary_year_avg</th><th>salary_hour_avg</th><th>company_name</th><th>job_skills</th><th>job_type_skills</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Senior Clinical Data Engineer …</td><td>&quot;Watertown, CT&quot;</td><td>&quot;via Work Nearby&quot;</td><td>&quot;Full-time&quot;</td><td>false</td><td>&quot;Texas, United States&quot;</td><td>&quot;2023-06-16 13:44:15&quot;</td><td>false</td><td>false</td><td>&quot;United States&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Boehringer Ingelheim&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;Data Analyst&quot;</td><td>&quot;Data Analyst&quot;</td><td>&quot;Guadalajara, Jalisco, Mexico&quot;</td><td>&quot;via BeBee México&quot;</td><td>&quot;Full-time&quot;</td><td>false</td><td>&quot;Mexico&quot;</td><td>&quot;2023-01-14 13:18:07&quot;</td><td>false</td><td>false</td><td>&quot;Mexico&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Hewlett Packard Enterprise&quot;</td><td>&quot;[&#x27;r&#x27;, &#x27;python&#x27;, &#x27;sql&#x27;, &#x27;nosql&#x27;…</td><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;power bi&#x27;,…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Data Engineer/Scientist/Analys…</td><td>&quot;Berlin, Germany&quot;</td><td>&quot;via LinkedIn&quot;</td><td>&quot;Full-time&quot;</td><td>false</td><td>&quot;Germany&quot;</td><td>&quot;2023-10-10 13:14:55&quot;</td><td>false</td><td>false</td><td>&quot;Germany&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;ALPHA Augmented Services&quot;</td><td>&quot;[&#x27;python&#x27;, &#x27;sql&#x27;, &#x27;c#&#x27;, &#x27;azure…</td><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;dax&#x27;], &#x27;cl…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;LEAD ENGINEER - PRINCIPAL ANAL…</td><td>&quot;San Antonio, TX&quot;</td><td>&quot;via Diversity.com&quot;</td><td>&quot;Full-time&quot;</td><td>false</td><td>&quot;Texas, United States&quot;</td><td>&quot;2023-07-04 13:01:41&quot;</td><td>true</td><td>false</td><td>&quot;United States&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Southwest Research Institute&quot;</td><td>&quot;[&#x27;python&#x27;, &#x27;c++&#x27;, &#x27;java&#x27;, &#x27;mat…</td><td>&quot;{&#x27;cloud&#x27;: [&#x27;aws&#x27;], &#x27;libraries&#x27;…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Data Engineer- Sr Jobs&quot;</td><td>&quot;Washington, DC&quot;</td><td>&quot;via Clearance Jobs&quot;</td><td>&quot;Full-time&quot;</td><td>false</td><td>&quot;Sudan&quot;</td><td>&quot;2023-08-07 14:29:36&quot;</td><td>false</td><td>false</td><td>&quot;Sudan&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Kristina Daniel&quot;</td><td>&quot;[&#x27;bash&#x27;, &#x27;python&#x27;, &#x27;oracle&#x27;, &#x27;…</td><td>&quot;{&#x27;cloud&#x27;: [&#x27;oracle&#x27;, &#x27;aws&#x27;], &#x27;…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Software Engineer&quot;</td><td>&quot;DevOps Engineer&quot;</td><td>&quot;Singapura&quot;</td><td>&quot;melalui Trabajo.org&quot;</td><td>&quot;Pekerjaan tetap&quot;</td><td>false</td><td>&quot;Singapore&quot;</td><td>&quot;2023-03-13 06:16:16&quot;</td><td>false</td><td>false</td><td>&quot;Singapore&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;CAREERSTAR INTERNATIONAL PTE. …</td><td>&quot;[&#x27;bash&#x27;, &#x27;python&#x27;, &#x27;perl&#x27;, &#x27;li…</td><td>&quot;{&#x27;os&#x27;: [&#x27;linux&#x27;, &#x27;unix&#x27;], &#x27;oth…</td></tr><tr><td>&quot;Data Analyst&quot;</td><td>&quot;CRM Data Analyst&quot;</td><td>&quot;Bad Rodach, Jerman&quot;</td><td>&quot;melalui BeBee Deutschland&quot;</td><td>&quot;Pekerjaan tetap&quot;</td><td>false</td><td>&quot;Germany&quot;</td><td>&quot;2023-03-12 06:18:18&quot;</td><td>false</td><td>false</td><td>&quot;Germany&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;HABA FAMILYGROUP&quot;</td><td>&quot;[&#x27;sas&#x27;, &#x27;sas&#x27;, &#x27;sql&#x27;, &#x27;excel&#x27;]&quot;</td><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;sas&#x27;, &#x27;exc…</td></tr><tr><td>&quot;Business Analyst&quot;</td><td>&quot;Commercial Analyst - Start Now&quot;</td><td>&quot;Malaysia&quot;</td><td>&quot;melalui Ricebowl&quot;</td><td>&quot;Pekerjaan tetap&quot;</td><td>false</td><td>&quot;Malaysia&quot;</td><td>&quot;2023-03-12 06:32:36&quot;</td><td>false</td><td>false</td><td>&quot;Malaysia&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Lendlease Corporation&quot;</td><td>&quot;[&#x27;powerpoint&#x27;, &#x27;excel&#x27;]&quot;</td><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;powerpoint…</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Principal Associate, Data Engi…</td><td>&quot;Newark, New Jersey, Amerika Se…</td><td>&quot;melalui Recruit.net&quot;</td><td>&quot;Pekerjaan tetap&quot;</td><td>false</td><td>&quot;Sudan&quot;</td><td>&quot;2023-03-12 06:32:15&quot;</td><td>false</td><td>false</td><td>&quot;Sudan&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Capital One&quot;</td><td>&quot;[&#x27;python&#x27;, &#x27;go&#x27;, &#x27;nosql&#x27;, &#x27;sql…</td><td>&quot;{&#x27;cloud&#x27;: [&#x27;aws&#x27;, &#x27;snowflake&#x27;,…</td></tr><tr><td>&quot;Software Engineer&quot;</td><td>&quot;AWS System Analyst&quot;</td><td>&quot;India&quot;</td><td>&quot;melalui Trigyn&quot;</td><td>&quot;Pekerjaan tetap&quot;</td><td>false</td><td>&quot;India&quot;</td><td>&quot;2023-03-13 06:16:31&quot;</td><td>false</td><td>false</td><td>&quot;India&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Trigyn&quot;</td><td>&quot;[&#x27;aws&#x27;, &#x27;flow&#x27;]&quot;</td><td>&quot;{&#x27;cloud&#x27;: [&#x27;aws&#x27;], &#x27;other&#x27;: [&#x27;…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (785_741, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ job_title ┆ job_title ┆ job_locat ┆ job_via   ┆ … ┆ salary_ho ┆ company_n ┆ job_skill ┆ job_type │\n",
       "│ _short    ┆ ---       ┆ ion       ┆ ---       ┆   ┆ ur_avg    ┆ ame       ┆ s         ┆ _skills  │\n",
       "│ ---       ┆ str       ┆ ---       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆           ┆ str       ┆           ┆   ┆ f64       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Senior    ┆ Senior    ┆ Watertown ┆ via Work  ┆ … ┆ null      ┆ Boehringe ┆ null      ┆ null     │\n",
       "│ Data      ┆ Clinical  ┆ , CT      ┆ Nearby    ┆   ┆           ┆ r         ┆           ┆          │\n",
       "│ Engineer  ┆ Data      ┆           ┆           ┆   ┆           ┆ Ingelheim ┆           ┆          │\n",
       "│           ┆ Engineer  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ Data      ┆ Data      ┆ Guadalaja ┆ via BeBee ┆ … ┆ null      ┆ Hewlett   ┆ ['r',     ┆ {'analys │\n",
       "│ Analyst   ┆ Analyst   ┆ ra,       ┆ México    ┆   ┆           ┆ Packard   ┆ 'python', ┆ t_tools' │\n",
       "│           ┆           ┆ Jalisco,  ┆           ┆   ┆           ┆ Enterpris ┆ 'sql',    ┆ :        │\n",
       "│           ┆           ┆ Mexico    ┆           ┆   ┆           ┆ e         ┆ 'nosql'…  ┆ ['power  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ bi',…    │\n",
       "│ Data      ┆ Data Engi ┆ Berlin,   ┆ via       ┆ … ┆ null      ┆ ALPHA     ┆ ['python' ┆ {'analys │\n",
       "│ Engineer  ┆ neer/Scie ┆ Germany   ┆ LinkedIn  ┆   ┆           ┆ Augmented ┆ , 'sql',  ┆ t_tools' │\n",
       "│           ┆ ntist/Ana ┆           ┆           ┆   ┆           ┆ Services  ┆ 'c#',     ┆ :        │\n",
       "│           ┆ lys…      ┆           ┆           ┆   ┆           ┆           ┆ 'azure…   ┆ ['dax'], │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 'cl…     │\n",
       "│ Data      ┆ LEAD      ┆ San       ┆ via Diver ┆ … ┆ null      ┆ Southwest ┆ ['python' ┆ {'cloud' │\n",
       "│ Engineer  ┆ ENGINEER  ┆ Antonio,  ┆ sity.com  ┆   ┆           ┆ Research  ┆ , 'c++',  ┆ :        │\n",
       "│           ┆ -         ┆ TX        ┆           ┆   ┆           ┆ Institute ┆ 'java',   ┆ ['aws'], │\n",
       "│           ┆ PRINCIPAL ┆           ┆           ┆   ┆           ┆           ┆ 'mat…     ┆ 'librari │\n",
       "│           ┆ ANAL…     ┆           ┆           ┆   ┆           ┆           ┆           ┆ es'…     │\n",
       "│ Data      ┆ Data      ┆ Washingto ┆ via       ┆ … ┆ null      ┆ Kristina  ┆ ['bash',  ┆ {'cloud' │\n",
       "│ Engineer  ┆ Engineer- ┆ n, DC     ┆ Clearance ┆   ┆           ┆ Daniel    ┆ 'python', ┆ : ['orac │\n",
       "│           ┆ Sr Jobs   ┆           ┆ Jobs      ┆   ┆           ┆           ┆ 'oracle', ┆ le',     │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ '…        ┆ 'aws'],  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ '…       │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ Software  ┆ DevOps    ┆ Singapura ┆ melalui   ┆ … ┆ null      ┆ CAREERSTA ┆ ['bash',  ┆ {'os':   │\n",
       "│ Engineer  ┆ Engineer  ┆           ┆ Trabajo.o ┆   ┆           ┆ R INTERNA ┆ 'python', ┆ ['linux' │\n",
       "│           ┆           ┆           ┆ rg        ┆   ┆           ┆ TIONAL    ┆ 'perl',   ┆ ,        │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ PTE. …    ┆ 'li…      ┆ 'unix'], │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 'oth…    │\n",
       "│ Data      ┆ CRM Data  ┆ Bad       ┆ melalui   ┆ … ┆ null      ┆ HABA FAMI ┆ ['sas',   ┆ {'analys │\n",
       "│ Analyst   ┆ Analyst   ┆ Rodach,   ┆ BeBee Deu ┆   ┆           ┆ LYGROUP   ┆ 'sas',    ┆ t_tools' │\n",
       "│           ┆           ┆ Jerman    ┆ tschland  ┆   ┆           ┆           ┆ 'sql',    ┆ :        │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 'excel']  ┆ ['sas',  │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 'exc…    │\n",
       "│ Business  ┆ Commercia ┆ Malaysia  ┆ melalui   ┆ … ┆ null      ┆ Lendlease ┆ ['powerpo ┆ {'analys │\n",
       "│ Analyst   ┆ l Analyst ┆           ┆ Ricebowl  ┆   ┆           ┆ Corporati ┆ int',     ┆ t_tools' │\n",
       "│           ┆ - Start   ┆           ┆           ┆   ┆           ┆ on        ┆ 'excel']  ┆ : ['powe │\n",
       "│           ┆ Now       ┆           ┆           ┆   ┆           ┆           ┆           ┆ rpoint…  │\n",
       "│ Data      ┆ Principal ┆ Newark,   ┆ melalui   ┆ … ┆ null      ┆ Capital   ┆ ['python' ┆ {'cloud' │\n",
       "│ Engineer  ┆ Associate ┆ New       ┆ Recruit.n ┆   ┆           ┆ One       ┆ , 'go',   ┆ :        │\n",
       "│           ┆ , Data    ┆ Jersey,   ┆ et        ┆   ┆           ┆           ┆ 'nosql',  ┆ ['aws',  │\n",
       "│           ┆ Engi…     ┆ Amerika   ┆           ┆   ┆           ┆           ┆ 'sql…     ┆ 'snowfla │\n",
       "│           ┆           ┆ Se…       ┆           ┆   ┆           ┆           ┆           ┆ ke',…    │\n",
       "│ Software  ┆ AWS       ┆ India     ┆ melalui   ┆ … ┆ null      ┆ Trigyn    ┆ ['aws',   ┆ {'cloud' │\n",
       "│ Engineer  ┆ System    ┆           ┆ Trigyn    ┆   ┆           ┆           ┆ 'flow']   ┆ :        │\n",
       "│           ┆ Analyst   ┆           ┆           ┆   ┆           ┆           ┆           ┆ ['aws'], │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 'other': │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ ['…      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet(\n",
    "    \"https://github.com/bdi593/datasets/raw/refs/heads/main/data-jobs/data_jobs.parquet\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17ad72",
   "metadata": {},
   "source": [
    "### Check the Number of Rows\n",
    "\n",
    "The number of rows and columns in the dataset can be checked using the `shape` attribute of the Polars DataFrame. The `shape` attribute returns a tuple containing the number of rows and columns in the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d829546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785741, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda1ac4",
   "metadata": {},
   "source": [
    "### Check Schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418679f",
   "metadata": {},
   "source": [
    "Check the schema to understand the data types of each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971a5f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schema([('job_title_short', String),\n",
       "        ('job_title', String),\n",
       "        ('job_location', String),\n",
       "        ('job_via', String),\n",
       "        ('job_schedule_type', String),\n",
       "        ('job_work_from_home', Boolean),\n",
       "        ('search_location', String),\n",
       "        ('job_posted_date', String),\n",
       "        ('job_no_degree_mention', Boolean),\n",
       "        ('job_health_insurance', Boolean),\n",
       "        ('job_country', String),\n",
       "        ('salary_rate', String),\n",
       "        ('salary_year_avg', Float64),\n",
       "        ('salary_hour_avg', Float64),\n",
       "        ('company_name', String),\n",
       "        ('job_skills', String),\n",
       "        ('job_type_skills', String)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639704ae",
   "metadata": {},
   "source": [
    "## Preprocess Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253beb5",
   "metadata": {},
   "source": [
    "### Check Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb968238",
   "metadata": {},
   "source": [
    "Check the number of missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f8869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_title_short</th><th>job_title</th><th>job_location</th><th>job_via</th><th>job_schedule_type</th><th>job_work_from_home</th><th>search_location</th><th>job_posted_date</th><th>job_no_degree_mention</th><th>job_health_insurance</th><th>job_country</th><th>salary_rate</th><th>salary_year_avg</th><th>salary_hour_avg</th><th>company_name</th><th>job_skills</th><th>job_type_skills</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>1</td><td>1045</td><td>8</td><td>12667</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>49</td><td>752674</td><td>763738</td><td>775079</td><td>1</td><td>117037</td><td>117037</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 17)\n",
       "┌────────────┬───────────┬───────────┬─────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ job_title_ ┆ job_title ┆ job_locat ┆ job_via ┆ … ┆ salary_ho ┆ company_n ┆ job_skill ┆ job_type_ │\n",
       "│ short      ┆ ---       ┆ ion       ┆ ---     ┆   ┆ ur_avg    ┆ ame       ┆ s         ┆ skills    │\n",
       "│ ---        ┆ u32       ┆ ---       ┆ u32     ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ u32        ┆           ┆ u32       ┆         ┆   ┆ u32       ┆ u32       ┆ u32       ┆ u32       │\n",
       "╞════════════╪═══════════╪═══════════╪═════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0          ┆ 1         ┆ 1045      ┆ 8       ┆ … ┆ 775079    ┆ 1         ┆ 117037    ┆ 117037    │\n",
       "└────────────┴───────────┴───────────┴─────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85040e22",
   "metadata": {},
   "source": [
    "The output is in a \"wide\" format, which makes it difficult to compare the number of missing values across columns. We can transpose the output to make it easier to read and analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae99eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (17, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>column_0</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;job_title_short&quot;</td><td>0</td></tr><tr><td>&quot;job_title&quot;</td><td>1</td></tr><tr><td>&quot;job_location&quot;</td><td>1045</td></tr><tr><td>&quot;job_via&quot;</td><td>8</td></tr><tr><td>&quot;job_schedule_type&quot;</td><td>12667</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;salary_year_avg&quot;</td><td>763738</td></tr><tr><td>&quot;salary_hour_avg&quot;</td><td>775079</td></tr><tr><td>&quot;company_name&quot;</td><td>1</td></tr><tr><td>&quot;job_skills&quot;</td><td>117037</td></tr><tr><td>&quot;job_type_skills&quot;</td><td>117037</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (17, 2)\n",
       "┌───────────────────┬──────────┐\n",
       "│ column            ┆ column_0 │\n",
       "│ ---               ┆ ---      │\n",
       "│ str               ┆ u32      │\n",
       "╞═══════════════════╪══════════╡\n",
       "│ job_title_short   ┆ 0        │\n",
       "│ job_title         ┆ 1        │\n",
       "│ job_location      ┆ 1045     │\n",
       "│ job_via           ┆ 8        │\n",
       "│ job_schedule_type ┆ 12667    │\n",
       "│ …                 ┆ …        │\n",
       "│ salary_year_avg   ┆ 763738   │\n",
       "│ salary_hour_avg   ┆ 775079   │\n",
       "│ company_name      ┆ 1        │\n",
       "│ job_skills        ┆ 117037   │\n",
       "│ job_type_skills   ┆ 117037   │\n",
       "└───────────────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count().transpose(include_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564b42a",
   "metadata": {},
   "source": [
    "We can go one step further and only display columns with one or more missing values to focus our attention on the columns that require preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83694bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>null_count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;job_title&quot;</td><td>1</td></tr><tr><td>&quot;job_location&quot;</td><td>1045</td></tr><tr><td>&quot;job_via&quot;</td><td>8</td></tr><tr><td>&quot;job_schedule_type&quot;</td><td>12667</td></tr><tr><td>&quot;job_country&quot;</td><td>49</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;salary_year_avg&quot;</td><td>763738</td></tr><tr><td>&quot;salary_hour_avg&quot;</td><td>775079</td></tr><tr><td>&quot;company_name&quot;</td><td>1</td></tr><tr><td>&quot;job_skills&quot;</td><td>117037</td></tr><tr><td>&quot;job_type_skills&quot;</td><td>117037</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 2)\n",
       "┌───────────────────┬────────────┐\n",
       "│ column            ┆ null_count │\n",
       "│ ---               ┆ ---        │\n",
       "│ str               ┆ u32        │\n",
       "╞═══════════════════╪════════════╡\n",
       "│ job_title         ┆ 1          │\n",
       "│ job_location      ┆ 1045       │\n",
       "│ job_via           ┆ 8          │\n",
       "│ job_schedule_type ┆ 12667      │\n",
       "│ job_country       ┆ 49         │\n",
       "│ …                 ┆ …          │\n",
       "│ salary_year_avg   ┆ 763738     │\n",
       "│ salary_hour_avg   ┆ 775079     │\n",
       "│ company_name      ┆ 1          │\n",
       "│ job_skills        ┆ 117037     │\n",
       "│ job_type_skills   ┆ 117037     │\n",
       "└───────────────────┴────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df.null_count()\n",
    "    .transpose(include_header=True, header_name=\"column\", column_names=[\"null_count\"])\n",
    "    .filter(pl.col(\"null_count\") > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a2856",
   "metadata": {},
   "source": [
    "While the output is helpful, the number of rows displayed in the output is limited to 10 rows by default by Polars. There are more columns with missing values that are not displayed in the output. To see all columns with missing values, we can temporarily set the maximum number of rows to display to a higher value, such as 50, to ensure that all columns with missing values are shown in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5410a04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>null_count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;job_title&quot;</td><td>1</td></tr><tr><td>&quot;job_location&quot;</td><td>1045</td></tr><tr><td>&quot;job_via&quot;</td><td>8</td></tr><tr><td>&quot;job_schedule_type&quot;</td><td>12667</td></tr><tr><td>&quot;job_country&quot;</td><td>49</td></tr><tr><td>&quot;salary_rate&quot;</td><td>752674</td></tr><tr><td>&quot;salary_year_avg&quot;</td><td>763738</td></tr><tr><td>&quot;salary_hour_avg&quot;</td><td>775079</td></tr><tr><td>&quot;company_name&quot;</td><td>1</td></tr><tr><td>&quot;job_skills&quot;</td><td>117037</td></tr><tr><td>&quot;job_type_skills&quot;</td><td>117037</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11, 2)\n",
       "┌───────────────────┬────────────┐\n",
       "│ column            ┆ null_count │\n",
       "│ ---               ┆ ---        │\n",
       "│ str               ┆ u32        │\n",
       "╞═══════════════════╪════════════╡\n",
       "│ job_title         ┆ 1          │\n",
       "│ job_location      ┆ 1045       │\n",
       "│ job_via           ┆ 8          │\n",
       "│ job_schedule_type ┆ 12667      │\n",
       "│ job_country       ┆ 49         │\n",
       "│ salary_rate       ┆ 752674     │\n",
       "│ salary_year_avg   ┆ 763738     │\n",
       "│ salary_hour_avg   ┆ 775079     │\n",
       "│ company_name      ┆ 1          │\n",
       "│ job_skills        ┆ 117037     │\n",
       "│ job_type_skills   ┆ 117037     │\n",
       "└───────────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display up to 50 rows of the null count table\n",
    "with pl.Config(tbl_rows=50):\n",
    "    display(\n",
    "        (\n",
    "            df.null_count()\n",
    "            .transpose(\n",
    "                include_header=True, header_name=\"column\", column_names=[\"null_count\"]\n",
    "            )\n",
    "            .filter(pl.col(\"null_count\") > 0)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb08449",
   "metadata": {},
   "source": [
    ":::{tip} What does the `with` statement do in Python?\n",
    "\n",
    "The `with` statement in Python is used to wrap the execution of a block of code with methods defined by a context manager. It is commonly used for resource management, such as opening files or managing database connections, ensuring that resources are properly released after their use, even if an error occurs.\n",
    "\n",
    "In the code example above, the `with` statement is used to temporarily set the maximum number of rows displayed in the output to 50. This means that when the block of code inside the `with` statement is executed, 50 rows of the DataFrame will be shown in the output, regardless of how many rows are actually in the DataFrame. After the block of code is executed, the maximum number of rows displayed will return to its previous setting.\n",
    "\n",
    "The default maximum number of rows displayed in Polars is 10, so using the `with` statement allows you to temporarily change this setting for a specific block of code without affecting the global configuration.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7819f40",
   "metadata": {},
   "source": [
    "### Drop Rows with Missing Job Title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf714e",
   "metadata": {},
   "source": [
    "There is one row with a null value in the `job_title` column. Filter the DataFrame to show only this row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce4da69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 17)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_title_short</th><th>job_title</th><th>job_location</th><th>job_via</th><th>job_schedule_type</th><th>job_work_from_home</th><th>search_location</th><th>job_posted_date</th><th>job_no_degree_mention</th><th>job_health_insurance</th><th>job_country</th><th>salary_rate</th><th>salary_year_avg</th><th>salary_hour_avg</th><th>company_name</th><th>job_skills</th><th>job_type_skills</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>bool</td><td>bool</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Data Engineer&quot;</td><td>null</td><td>null</td><td>&quot;via Jobs In France - Mustakbil…</td><td>null</td><td>false</td><td>&quot;Saint Lucia&quot;</td><td>&quot;2023-12-14 07:32:05&quot;</td><td>false</td><td>false</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 17)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ job_title ┆ job_title ┆ job_locat ┆ job_via   ┆ … ┆ salary_ho ┆ company_n ┆ job_skill ┆ job_type │\n",
       "│ _short    ┆ ---       ┆ ion       ┆ ---       ┆   ┆ ur_avg    ┆ ame       ┆ s         ┆ _skills  │\n",
       "│ ---       ┆ str       ┆ ---       ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆           ┆ str       ┆           ┆   ┆ f64       ┆ str       ┆ str       ┆ str      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Data      ┆ null      ┆ null      ┆ via Jobs  ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ Engineer  ┆           ┆           ┆ In France ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ - Mustakb ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ il…       ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df[\"job_title\"].is_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0d03",
   "metadata": {},
   "source": [
    "The dataset has over 780,000 rows, but only one row has a null value in the `job_title` and the `company` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a953333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']\",)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"job_skills\").is_not_null()).select(pl.col(\"job_skills\")).row(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba5cb54",
   "metadata": {},
   "source": [
    "### Parse `\"job_posted_date\"` Column\n",
    "\n",
    "The `\"job_posted_date\"` column contains date information in string format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e307b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_posted_date</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;2023-06-16 13:44:15&quot;</td></tr><tr><td>&quot;2023-01-14 13:18:07&quot;</td></tr><tr><td>&quot;2023-10-10 13:14:55&quot;</td></tr><tr><td>&quot;2023-07-04 13:01:41&quot;</td></tr><tr><td>&quot;2023-08-07 14:29:36&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5,)\n",
       "Series: 'job_posted_date' [str]\n",
       "[\n",
       "\t\"2023-06-16 13:44:15\"\n",
       "\t\"2023-01-14 13:18:07\"\n",
       "\t\"2023-10-10 13:14:55\"\n",
       "\t\"2023-07-04 13:01:41\"\n",
       "\t\"2023-08-07 14:29:36\"\n",
       "]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"job_posted_date\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea265bd4",
   "metadata": {},
   "source": [
    "Check the data type of the `\"job_posted_date\"` column to confirm that it is currently stored as a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77a01876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_posted_date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ea9f3",
   "metadata": {},
   "source": [
    "We can parse this column into a proper date format using the `pl.col().str.strptime()` method in Polars, which allows us to specify the date format and handle any parsing errors gracefully.\n",
    "\n",
    "If you don't specify the date format, Polars will attempt to infer the format. Since the date format in the `\"job_posted_date\"` column is consistent (e.g., \"2023-06-16 13:44:15\"), Polars should be able to parse it correctly without explicitly providing the format.\n",
    "\n",
    "However, if you want to ensure that the parsing is done correctly and to handle any potential variations in date formats, you can specify the format using the `format` parameter in the `str.strptime()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_posted_date</th></tr><tr><td>datetime[μs]</td></tr></thead><tbody><tr><td>2023-06-16 13:44:15</td></tr><tr><td>2023-01-14 13:18:07</td></tr><tr><td>2023-10-10 13:14:55</td></tr><tr><td>2023-07-04 13:01:41</td></tr><tr><td>2023-08-07 14:29:36</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌─────────────────────┐\n",
       "│ job_posted_date     │\n",
       "│ ---                 │\n",
       "│ datetime[μs]        │\n",
       "╞═════════════════════╡\n",
       "│ 2023-06-16 13:44:15 │\n",
       "│ 2023-01-14 13:18:07 │\n",
       "│ 2023-10-10 13:14:55 │\n",
       "│ 2023-07-04 13:01:41 │\n",
       "│ 2023-08-07 14:29:36 │\n",
       "└─────────────────────┘"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns(pl.col(\"job_posted_date\").str.to_datetime())\n",
    "\n",
    "df.select(pl.col(\"job_posted_date\")).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0235709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime(time_unit='us', time_zone=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_posted_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a266239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_posted_date</th></tr><tr><td>struct[2]</td></tr></thead><tbody><tr><td>{3,64084}</td></tr><tr><td>{9,62359}</td></tr><tr><td>{2,64578}</td></tr><tr><td>{10,66611}</td></tr><tr><td>{8,75162}</td></tr><tr><td>&hellip;</td></tr><tr><td>{4,62919}</td></tr><tr><td>{7,63777}</td></tr><tr><td>{6,61572}</td></tr><tr><td>{1,91822}</td></tr><tr><td>{11,64450}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 1)\n",
       "┌─────────────────┐\n",
       "│ job_posted_date │\n",
       "│ ---             │\n",
       "│ struct[2]       │\n",
       "╞═════════════════╡\n",
       "│ {3,64084}       │\n",
       "│ {9,62359}       │\n",
       "│ {2,64578}       │\n",
       "│ {10,66611}      │\n",
       "│ {8,75162}       │\n",
       "│ …               │\n",
       "│ {4,62919}       │\n",
       "│ {7,63777}       │\n",
       "│ {6,61572}       │\n",
       "│ {1,91822}       │\n",
       "│ {11,64450}      │\n",
       "└─────────────────┘"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col(\"job_posted_date\").dt.month().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66732fe",
   "metadata": {},
   "source": [
    "### Parse `\"job_skills\"` Column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f2538",
   "metadata": {},
   "source": [
    "The `\"job_skills\"` column is stored as a string that looks like a list, but it is not actually a list data type.\n",
    "\n",
    "We can check the data type of the `\"job_skills\"` column to confirm that it is currently stored as a string. The output should indicate that the data type of the `\"job_skills\"` column is `String`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e412db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_skills</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;[&#x27;r&#x27;, &#x27;python&#x27;, &#x27;sql&#x27;, &#x27;nosql&#x27;…</td></tr><tr><td>&quot;[&#x27;python&#x27;, &#x27;sql&#x27;, &#x27;c#&#x27;, &#x27;azure…</td></tr><tr><td>&quot;[&#x27;python&#x27;, &#x27;c++&#x27;, &#x27;java&#x27;, &#x27;mat…</td></tr><tr><td>&quot;[&#x27;bash&#x27;, &#x27;python&#x27;, &#x27;oracle&#x27;, &#x27;…</td></tr><tr><td>&quot;[&#x27;python&#x27;, &#x27;sql&#x27;, &#x27;gcp&#x27;]&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌─────────────────────────────────┐\n",
       "│ job_skills                      │\n",
       "│ ---                             │\n",
       "│ str                             │\n",
       "╞═════════════════════════════════╡\n",
       "│ ['r', 'python', 'sql', 'nosql'… │\n",
       "│ ['python', 'sql', 'c#', 'azure… │\n",
       "│ ['python', 'c++', 'java', 'mat… │\n",
       "│ ['bash', 'python', 'oracle', '… │\n",
       "│ ['python', 'sql', 'gcp']        │\n",
       "└─────────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"job_skills\").is_not_null()).select(pl.col(\"job_skills\")).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bf5435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea860992",
   "metadata": {},
   "source": [
    "To convert it to a list, we can use the `str.replace_all()` method to replace single quotes with double quotes, and then use the `str.json_decode()` method to parse the string as JSON. This will give us a proper list of skills for each job.\n",
    "\n",
    ":::{tip} Why do we need to replace single quotes with double quotes before parsing the string as JSON?\n",
    "\n",
    "The JSON format requires that string values be enclosed in double quotes. If the string uses single quotes, it will not be valid JSON and the `str.json_decode()` method will fail to parse it correctly. By replacing single quotes with double quotes, we ensure that the string conforms to the JSON format, allowing us to successfully decode it into a list data type.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd71500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_skills</th></tr><tr><td>list[str]</td></tr></thead><tbody><tr><td>[&quot;r&quot;, &quot;python&quot;, … &quot;tableau&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;, … &quot;jenkins&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;c++&quot;, … &quot;pytorch&quot;]</td></tr><tr><td>[&quot;bash&quot;, &quot;python&quot;, … &quot;git&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;, &quot;gcp&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌────────────────────────────────┐\n",
       "│ job_skills                     │\n",
       "│ ---                            │\n",
       "│ list[str]                      │\n",
       "╞════════════════════════════════╡\n",
       "│ [\"r\", \"python\", … \"tableau\"]   │\n",
       "│ [\"python\", \"sql\", … \"jenkins\"] │\n",
       "│ [\"python\", \"c++\", … \"pytorch\"] │\n",
       "│ [\"bash\", \"python\", … \"git\"]    │\n",
       "│ [\"python\", \"sql\", \"gcp\"]       │\n",
       "└────────────────────────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"job_skills\").is_not_null())\n",
    "    .then(\n",
    "        pl.col(\"job_skills\")\n",
    "        .str.replace_all(\"'\", '\"')\n",
    "        .str.json_decode(dtype=pl.List(pl.Utf8))\n",
    "    )\n",
    "    .otherwise(None)\n",
    "    .alias(\"job_skills\")\n",
    ")\n",
    "\n",
    "df.filter(pl.col(\"job_skills\").is_not_null()).select(pl.col(\"job_skills\")).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247c43a",
   "metadata": {},
   "source": [
    "Print the first non-null value in the `\"job_skills\"` column to see a non-truncated output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "232099d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col(\"job_skills\")).filter(pl.col(\"job_skills\").is_not_null()).row(0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38414e7",
   "metadata": {},
   "source": [
    "Verify that the `\"job_skills\"` column has been successfully parsed as a list by checking the data type of the column. The output should indicate that the data type of the `\"job_skills\"` column is now a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd0a897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(String)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a627ce",
   "metadata": {},
   "source": [
    "#### How many jobs require \"Python\" as a skill?\n",
    "\n",
    "We can use the `list.contains()` method to filter the DataFrame for rows where the `\"job_skills\"` list contains the skill \"Python\".\n",
    "\n",
    "The code below filters the DataFrame to include only rows where the `\"job_skills\"` column contains \"Python\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82fab72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (380_909, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_title</th><th>company_name</th><th>job_skills</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;Data Analyst&quot;</td><td>&quot;Hewlett Packard Enterprise&quot;</td><td>[&quot;r&quot;, &quot;python&quot;, … &quot;tableau&quot;]</td></tr><tr><td>&quot;Data Engineer/Scientist/Analys…</td><td>&quot;ALPHA Augmented Services&quot;</td><td>[&quot;python&quot;, &quot;sql&quot;, … &quot;jenkins&quot;]</td></tr><tr><td>&quot;LEAD ENGINEER - PRINCIPAL ANAL…</td><td>&quot;Southwest Research Institute&quot;</td><td>[&quot;python&quot;, &quot;c++&quot;, … &quot;pytorch&quot;]</td></tr><tr><td>&quot;Data Engineer- Sr Jobs&quot;</td><td>&quot;Kristina Daniel&quot;</td><td>[&quot;bash&quot;, &quot;python&quot;, … &quot;git&quot;]</td></tr><tr><td>&quot;GCP Data Engineer&quot;</td><td>&quot;smart folks inc&quot;</td><td>[&quot;python&quot;, &quot;sql&quot;, &quot;gcp&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Data Engineer&quot;</td><td>&quot;Shamrock Trading Corporation&quot;</td><td>[&quot;nosql&quot;, &quot;mongodb&quot;, … &quot;git&quot;]</td></tr><tr><td>&quot;Data Engineer (f/m/d)&quot;</td><td>&quot;Heidelberg Materials&quot;</td><td>[&quot;python&quot;, &quot;c#&quot;, … &quot;terraform&quot;]</td></tr><tr><td>&quot;Senior Data Engineer&quot;</td><td>&quot;Pure App&quot;</td><td>[&quot;sql&quot;, &quot;python&quot;, … &quot;docker&quot;]</td></tr><tr><td>&quot;DevOps Engineer&quot;</td><td>&quot;CAREERSTAR INTERNATIONAL PTE. …</td><td>[&quot;bash&quot;, &quot;python&quot;, … &quot;ansible&quot;]</td></tr><tr><td>&quot;Principal Associate, Data Engi…</td><td>&quot;Capital One&quot;</td><td>[&quot;python&quot;, &quot;go&quot;, … &quot;docker&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (380_909, 3)\n",
       "┌────────────────────────────┬──────────────────────────────────┬──────────────────────────────────┐\n",
       "│ job_title                  ┆ company_name                     ┆ job_skills                       │\n",
       "│ ---                        ┆ ---                              ┆ ---                              │\n",
       "│ str                        ┆ str                              ┆ list[str]                        │\n",
       "╞════════════════════════════╪══════════════════════════════════╪══════════════════════════════════╡\n",
       "│ Data Analyst               ┆ Hewlett Packard Enterprise       ┆ [\"r\", \"python\", … \"tableau\"]     │\n",
       "│ Data                       ┆ ALPHA Augmented Services         ┆ [\"python\", \"sql\", … \"jenkins\"]   │\n",
       "│ Engineer/Scientist/Analys… ┆                                  ┆                                  │\n",
       "│ LEAD ENGINEER - PRINCIPAL  ┆ Southwest Research Institute     ┆ [\"python\", \"c++\", … \"pytorch\"]   │\n",
       "│ ANAL…                      ┆                                  ┆                                  │\n",
       "│ Data Engineer- Sr Jobs     ┆ Kristina Daniel                  ┆ [\"bash\", \"python\", … \"git\"]      │\n",
       "│ GCP Data Engineer          ┆ smart folks inc                  ┆ [\"python\", \"sql\", \"gcp\"]         │\n",
       "│ …                          ┆ …                                ┆ …                                │\n",
       "│ Data Engineer              ┆ Shamrock Trading Corporation     ┆ [\"nosql\", \"mongodb\", … \"git\"]    │\n",
       "│ Data Engineer (f/m/d)      ┆ Heidelberg Materials             ┆ [\"python\", \"c#\", … \"terraform\"…  │\n",
       "│ Senior Data Engineer       ┆ Pure App                         ┆ [\"sql\", \"python\", … \"docker\"]    │\n",
       "│ DevOps Engineer            ┆ CAREERSTAR INTERNATIONAL PTE. …  ┆ [\"bash\", \"python\", … \"ansible\"…  │\n",
       "│ Principal Associate, Data  ┆ Capital One                      ┆ [\"python\", \"go\", … \"docker\"]     │\n",
       "│ Engi…                      ┆                                  ┆                                  │\n",
       "└────────────────────────────┴──────────────────────────────────┴──────────────────────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"job_skills\").list.contains(\"python\")).select(\n",
    "    pl.col(\"job_title\"), pl.col(\"company_name\"), pl.col(\"job_skills\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f32cce",
   "metadata": {},
   "source": [
    "The `height` attribute can be used to count the number of rows that match this condition.\n",
    "\n",
    "It is equivalent to using the `len()` function, or `.shape[0]` to get the number of rows in the filtered DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b258b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380909"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(pl.col(\"job_skills\").list.contains(\"python\")).height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615b6a0",
   "metadata": {},
   "source": [
    "### Parse `\"job_type_skills\"` column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb1c67",
   "metadata": {},
   "source": [
    "Similar to the `\"job_skills\"` column, the `\"job_type_skills\"` column is also stored as a string. However, the column contains dictionary-like string values as opposed to the list-like string values in the `\"job_skills\"` column.\n",
    "\n",
    "Print the first five non-null values in the `\"job_type_skills\"` column to understand its structure and confirm that it is stored as a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b31368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>job_type_skills</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;power bi&#x27;,…</td></tr><tr><td>&quot;{&#x27;analyst_tools&#x27;: [&#x27;dax&#x27;], &#x27;cl…</td></tr><tr><td>&quot;{&#x27;cloud&#x27;: [&#x27;aws&#x27;], &#x27;libraries&#x27;…</td></tr><tr><td>&quot;{&#x27;cloud&#x27;: [&#x27;oracle&#x27;, &#x27;aws&#x27;], &#x27;…</td></tr><tr><td>&quot;{&#x27;cloud&#x27;: [&#x27;gcp&#x27;], &#x27;programmin…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌─────────────────────────────────┐\n",
       "│ job_type_skills                 │\n",
       "│ ---                             │\n",
       "│ str                             │\n",
       "╞═════════════════════════════════╡\n",
       "│ {'analyst_tools': ['power bi',… │\n",
       "│ {'analyst_tools': ['dax'], 'cl… │\n",
       "│ {'cloud': ['aws'], 'libraries'… │\n",
       "│ {'cloud': ['oracle', 'aws'], '… │\n",
       "│ {'cloud': ['gcp'], 'programmin… │\n",
       "└─────────────────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"job_type_skills\").filter(pl.col(\"job_type_skills\").is_not_null()).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4564d5",
   "metadata": {},
   "source": [
    "To see a non-truncated view of the first row, retrieve the first non-null value in the `\"job_type_skills\"` column and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04cfa16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'analyst_tools': ['power bi', 'tableau'], 'programming': ['r', 'python', 'sql', 'nosql']}\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"job_type_skills\").filter(pl.col(\"job_type_skills\").is_not_null()).row(0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6712407",
   "metadata": {},
   "source": [
    "Check the data type of the `\"job_type_skills\"` column to confirm that it is currently stored as a string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e8402c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_type_skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfa26f",
   "metadata": {},
   "source": [
    "The output shows that the `\"job_type_skills\"` column contains string representations of dictionaries, where each dictionary has a job type as the key and a list of skills as the value. For example, one of the values is (added line breaks for readability):\n",
    "\n",
    "```\n",
    "\"{\n",
    "    'analyst_tools': ['power bi', 'tableau'],\n",
    "    'programming': ['r', 'python', 'sql', 'nosql']\n",
    "}\"\n",
    "```\n",
    "\n",
    "There are two keys in the dictionary: `\"analyst_tools\"` and `\"programming\"`. The value for each key is a list of skills relevant to that job type. For instance, the \"programming\" key has a list of programming languages and technologies such as \"r\", \"python\", \"sql\", and \"nosql\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1d5e3",
   "metadata": {},
   "source": [
    ":::{tip} Structs in Polars\n",
    "\n",
    "A `Struct` in Polars is:\n",
    "\n",
    "> A single column that contains multiple named, typed subcolumns.\n",
    "\n",
    "Example:\n",
    "\n",
    "`Struct({\n",
    "    analyst_tools: List(Utf8),\n",
    "    programming: List(Utf8)\n",
    "})`\n",
    "\n",
    "Visually:\n",
    "\n",
    "| job_type_skills                            |\n",
    "| ------------------------------------------ |\n",
    "| {analyst_tools: [...], programming: [...]} |\n",
    "| {analyst_tools: [...], programming: [...]} |\n",
    "\n",
    "But internally it is not stored row-by-row like Python dictionaries. While you don't need to understand the internal storage format of `Struct` to work with it, it is helpful to know that it is not stored as a string, but rather as a structured data type that allows for efficient querying and manipulation of the nested data.\n",
    "\n",
    "Polars is built on Apache Arrow, which is:\n",
    "\n",
    "- Columnar\n",
    "- Typed\n",
    "- Memory-contiguous\n",
    "- Zero-copy friendly\n",
    "\n",
    "A Polars `Struct` column's each field is stored as its own full column, which allows for efficient access and manipulation of the nested data without needing to parse strings or perform complex operations on row-by-row data.\n",
    "\n",
    "So instead of:\n",
    "\n",
    "```\n",
    "Row 1 → {a:1, b:2}\n",
    "Row 2 → {a:3, b:4}\n",
    "```\n",
    "\n",
    "Memory looks like:\n",
    "\n",
    "```\n",
    "a column → [1, 3]\n",
    "b column → [2, 4]\n",
    "```\n",
    "\n",
    "The struct is just a logical grouping.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4a21a",
   "metadata": {},
   "source": [
    ":::{attention} What if the dictionary-like string values have varying keys across rows?\n",
    "\n",
    "If the dictionary-like string values in the `\"job_type_skills\"` column have varying keys across rows, it can pose challenges for parsing and analyzing the data. In such cases, you may need to:\n",
    "\n",
    "1. **Approach 1**: Use a parser that converts a string containing a Python literal into an actual Python object, such as `ast.literal_eval()` from the `ast` module in Python. This function can safely evaluate a string containing a Python literal (like a dictionary) and convert it into the corresponding Python data structure.\n",
    "   - This will be more flexible if the keys in the dictionary-like string values vary widely across rows, as it can dynamically parse any valid Python literal. However, it may be less efficient and potentially unsafe if the input is not controlled, as it can execute arbitrary code if the input string is malicious.\n",
    "2. **Approach 2**: If you know all possible keys in advance, you can create a schema for the `Struct` and use conditional logic to handle missing keys when parsing the string values.\n",
    "\n",
    "- This is more efficient if the set of possible keys is limited and known, as it allows you to directly parse the string values into a structured format without needing to evaluate arbitrary Python literals, which can be less efficient and potentially unsafe if the input is not controlled.\n",
    "\n",
    "3. **Approach 3**: Find all unique keys across the dataset and create a schema that includes all possible keys, then parse the string values accordingly.\n",
    "   - While this is the slowest approach, it will ensure that you use a predefined schema for the `Struct` that includes all possible keys, allowing you to parse the string values into a structured format.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7150c94f",
   "metadata": {},
   "source": [
    "#### Approach 1: Use `ast.literal_eval()` to parse the string values into dictionaries\n",
    "\n",
    "The `ast.literal_eval()` function from the `ast` module in Python can be used to safely evaluate a string containing a Python literal (like a dictionary) and convert it into the corresponding Python data structure. This approach is flexible and can handle varying keys across rows, but it may be less efficient and potentially unsafe if the input is not controlled, as it can execute arbitrary code if the input string is malicious.\n",
    "\n",
    "Although the sample code is provided below, we will not run it in the notebook due to its slow execution time. You can try running it on your own machine if you have sufficient resources, but be aware that it may take a long time to execute.\n",
    "\n",
    ":::{danger} Slow execution warning!\n",
    "\n",
    "The code below uses `ast.literal_eval()` to parse the string values in the `\"job_type_skills\"` column into dictionaries, and use `%%time` to measure the execution time of this code block.\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "import ast\n",
    "\n",
    "df.with_columns(\n",
    "    pl.when(pl.col(\"job_type_skills\").is_not_null())\n",
    "    .then(\n",
    "        pl.col(\"job_type_skills\").map_elements(\n",
    "            ast.literal_eval,\n",
    "            return_dtype=pl.Object,  # important: avoid inference surprises\n",
    "        )\n",
    "    )\n",
    "    .otherwise(None)\n",
    "    .alias(\"job_type_skills\")\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ab091",
   "metadata": {},
   "source": [
    "#### Approach 2: Create a schema for the `Struct` in advance\n",
    "\n",
    "This approach can only be used if you know all possible keys in advance. Because we don't know all possible keys in the `\"job_type_skills\"` column, we will skip this approach for now. However, if you have a limited and known set of keys, you can create a schema for the `Struct` and use conditional logic to handle missing keys when parsing the string values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3fa72",
   "metadata": {},
   "source": [
    "#### Approach 3: Find all unique keys across the dataset and create a schema\n",
    "\n",
    "This will be the slowest approach, but it will allow you to create a `struct` type column instead of a generic `object` type column, which will enable you to work with the nested data more efficiently in Polars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b62591",
   "metadata": {},
   "source": [
    "First, find all unique keys across the dataset in the `\"job_type_skills\"` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03547ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 1.11 s, total: 19.6 s\n",
      "Wall time: 19.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>keys</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;databases&quot;</td></tr><tr><td>&quot;os&quot;</td></tr><tr><td>&quot;webframeworks&quot;</td></tr><tr><td>&quot;analyst_tools&quot;</td></tr><tr><td>&quot;programming&quot;</td></tr><tr><td>&quot;cloud&quot;</td></tr><tr><td>&quot;libraries&quot;</td></tr><tr><td>&quot;sync&quot;</td></tr><tr><td>&quot;async&quot;</td></tr><tr><td>&quot;other&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 1)\n",
       "┌───────────────┐\n",
       "│ keys          │\n",
       "│ ---           │\n",
       "│ str           │\n",
       "╞═══════════════╡\n",
       "│ databases     │\n",
       "│ os            │\n",
       "│ webframeworks │\n",
       "│ analyst_tools │\n",
       "│ programming   │\n",
       "│ cloud         │\n",
       "│ libraries     │\n",
       "│ sync          │\n",
       "│ async         │\n",
       "│ other         │\n",
       "└───────────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import ast\n",
    "\n",
    "keys = (\n",
    "    df.filter(pl.col(\"job_type_skills\").is_not_null())\n",
    "    .select(\n",
    "        pl.col(\"job_type_skills\")\n",
    "        .map_elements(ast.literal_eval, return_dtype=pl.Object)\n",
    "        .map_elements(lambda d: list(d.keys()), return_dtype=pl.List(pl.Utf8))\n",
    "        .alias(\"keys\")\n",
    "    )\n",
    "    .explode(\"keys\")\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c2535",
   "metadata": {},
   "source": [
    "Then, use the list of unique keys to create a schema for the `Struct` and parse the string values in the `\"job_type_skills\"` column accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40ee248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = keys.get_column(\"keys\").to_list()\n",
    "\n",
    "skills_struct_dtype = pl.Struct([pl.Field(k, pl.List(pl.Utf8)) for k in key_list])\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.when(pl.col(\"job_type_skills\").is_not_null())\n",
    "    .then(\n",
    "        pl.col(\"job_type_skills\")\n",
    "        .str.replace_all(\"'\", '\"')\n",
    "        .str.json_decode(dtype=skills_struct_dtype)\n",
    "    )\n",
    "    .otherwise(None)\n",
    "    .alias(\"job_type_skills\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3c22d",
   "metadata": {},
   "source": [
    "Confirm that the `\"job_type_skills\"` column has been successfully parsed as a `Struct` by checking the data type of the column. The output should indicate that the data type of the `\"job_type_skills\"` column is now a `Struct` with fields corresponding to the unique keys found in the previous step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cdc8de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct({'databases': List(String), 'os': List(String), 'webframeworks': List(String), 'analyst_tools': List(String), 'programming': List(String), 'cloud': List(String), 'libraries': List(String), 'sync': List(String), 'async': List(String), 'other': List(String)})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema[\"job_type_skills\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bca34",
   "metadata": {},
   "source": [
    "Print the first non-null value in the `\"job_type_skills\"` column to see the structured data format after parsing it as a `Struct`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d60b967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'databases': None,\n",
       " 'os': None,\n",
       " 'webframeworks': None,\n",
       " 'analyst_tools': ['power bi', 'tableau'],\n",
       " 'programming': ['r', 'python', 'sql', 'nosql'],\n",
       " 'cloud': None,\n",
       " 'libraries': None,\n",
       " 'sync': None,\n",
       " 'async': None,\n",
       " 'other': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col(\"job_type_skills\")).filter(\n",
    "    pl.col(\"job_type_skills\").is_not_null()\n",
    ").row(0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf137bf",
   "metadata": {},
   "source": [
    "The parsed `Struct` keeps all 10 keys, even if some rows have missing values for certain keys. This allows you to work with the nested data in a consistent way, regardless of whether all keys are present in every row. You can access the fields of the `Struct` using dot notation or by selecting specific fields as needed for your analysis.\n",
    "\n",
    "Below is an example of how to access the \"programming\" field of the `Struct` in the `\"job_type_skills\"` column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e90e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (785_741, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>programming</th></tr><tr><td>list[str]</td></tr></thead><tbody><tr><td>null</td></tr><tr><td>[&quot;r&quot;, &quot;python&quot;, … &quot;nosql&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;, &quot;c#&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;c++&quot;, … &quot;matlab&quot;]</td></tr><tr><td>[&quot;bash&quot;, &quot;python&quot;]</td></tr><tr><td>&hellip;</td></tr><tr><td>[&quot;bash&quot;, &quot;python&quot;, &quot;perl&quot;]</td></tr><tr><td>[&quot;sas&quot;, &quot;sql&quot;]</td></tr><tr><td>null</td></tr><tr><td>[&quot;python&quot;, &quot;go&quot;, … &quot;shell&quot;]</td></tr><tr><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (785_741, 1)\n",
       "┌───────────────────────────────┐\n",
       "│ programming                   │\n",
       "│ ---                           │\n",
       "│ list[str]                     │\n",
       "╞═══════════════════════════════╡\n",
       "│ null                          │\n",
       "│ [\"r\", \"python\", … \"nosql\"]    │\n",
       "│ [\"python\", \"sql\", \"c#\"]       │\n",
       "│ [\"python\", \"c++\", … \"matlab\"] │\n",
       "│ [\"bash\", \"python\"]            │\n",
       "│ …                             │\n",
       "│ [\"bash\", \"python\", \"perl\"]    │\n",
       "│ [\"sas\", \"sql\"]                │\n",
       "│ null                          │\n",
       "│ [\"python\", \"go\", … \"shell\"]   │\n",
       "│ null                          │\n",
       "└───────────────────────────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(pl.col(\"job_type_skills\").struct.field(\"programming\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd089f98",
   "metadata": {},
   "source": [
    "#### How many jobs require \"sql\" as a programming skill in the `\"job_type_skills\"` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd14236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (384_849, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>programming</th></tr><tr><td>list[str]</td></tr></thead><tbody><tr><td>[&quot;r&quot;, &quot;python&quot;, … &quot;nosql&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;, &quot;c#&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;]</td></tr><tr><td>[&quot;sql&quot;, &quot;python&quot;, &quot;java&quot;]</td></tr><tr><td>[&quot;sql&quot;, &quot;nosql&quot;]</td></tr><tr><td>&hellip;</td></tr><tr><td>[&quot;python&quot;, &quot;sql&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;c#&quot;, … &quot;sql&quot;]</td></tr><tr><td>[&quot;sql&quot;, &quot;python&quot;]</td></tr><tr><td>[&quot;sas&quot;, &quot;sql&quot;]</td></tr><tr><td>[&quot;python&quot;, &quot;go&quot;, … &quot;shell&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (384_849, 1)\n",
       "┌─────────────────────────────┐\n",
       "│ programming                 │\n",
       "│ ---                         │\n",
       "│ list[str]                   │\n",
       "╞═════════════════════════════╡\n",
       "│ [\"r\", \"python\", … \"nosql\"]  │\n",
       "│ [\"python\", \"sql\", \"c#\"]     │\n",
       "│ [\"python\", \"sql\"]           │\n",
       "│ [\"sql\", \"python\", \"java\"]   │\n",
       "│ [\"sql\", \"nosql\"]            │\n",
       "│ …                           │\n",
       "│ [\"python\", \"sql\"]           │\n",
       "│ [\"python\", \"c#\", … \"sql\"]   │\n",
       "│ [\"sql\", \"python\"]           │\n",
       "│ [\"sas\", \"sql\"]              │\n",
       "│ [\"python\", \"go\", … \"shell\"] │\n",
       "└─────────────────────────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_skill_required = df.filter(\n",
    "    pl.col(\"job_type_skills\").struct.field(\"programming\").list.contains(\"sql\")\n",
    ").select(pl.col(\"job_type_skills\").struct.field(\"programming\").alias(\"programming\"))\n",
    "\n",
    "sql_skill_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a40ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs that require 'sql' as a programming skill: 384849 out of 785741 total jobs (49.0%).\n"
     ]
    }
   ],
   "source": [
    "num_sql_required = sql_skill_required.height\n",
    "print(\n",
    "    f\"Number of jobs that require 'sql' as a programming skill: {num_sql_required} out of {df.height} total jobs ({num_sql_required / df.height:.1%}).\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
